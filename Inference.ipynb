{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f40cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d858ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth(input_df):\n",
    "    # Extract the \"isfraud\" column from the input DataFrame\n",
    "    return input_df[\"isfraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ced8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(input_df, categorical_column):\n",
    "    # Step 1: StringIndexer to convert categorical values to numerical indices\n",
    "    indexer = StringIndexer(inputCol=categorical_column, outputCol=\"categoryIndex\")\n",
    "    \n",
    "    # Fit and transform the indexer on your DataFrame\n",
    "    indexed_df = indexer.fit(input_df).transform(input_df)\n",
    "\n",
    "    # Step 2: OneHotEncoder to perform one-hot encoding\n",
    "    encoder = OneHotEncoder(inputCol=\"categoryIndex\", outputCol=\"encoded_\" + categorical_column)\n",
    "    \n",
    "    # Fit and transform the encoder on your DataFrame\n",
    "    encoded_df = encoder.transform(indexed_df)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    encoded_df = encoded_df.drop(categorical_column)\n",
    "    encoded_df = encoded_df.drop(\"categoryIndex\")\n",
    "\n",
    "    # Define the feature columns (excluding the target column \"isfraud\")\n",
    "    feature_columns = [col for col in encoded_df.columns if col != \"isfraud\"]\n",
    "    \n",
    "    # Assemble feature vector\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "    assembled_df = assembler.transform(encoded_df)\n",
    "\n",
    "    return assembled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230c09c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = PipelineModel.load(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APP\n",
    "spark = SparkSession.builder.appName(\"spark-predictions\").enableHiveSupport().getOrCreate()\n",
    "df = spark.sql(\"SELECT * FROM fraud_project\")\n",
    "categorical_column = \"transaction_type\"\n",
    "\n",
    "#Preprocessed DataFrame\n",
    "preprocessed_df = preprocess_data(df, categorical_column)\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predictions = loaded_model.transform(preprocessed_df)\n",
    "\n",
    "#Ground Truth\n",
    "ground_truth = ground_truth(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca63e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for predictions and ground truth\n",
    "predictions_df = spark.createDataFrame(predictions, [\"predictions\"])\n",
    "ground_truth_df = spark.createDataFrame(ground_truth, [\"ground_truth\"])\n",
    "\n",
    "# Add auto-incrementing ID columns\n",
    "predictions_df = predictions_df.withColumn(\"ID\", monotonically_increasing_id())\n",
    "ground_truth_df = ground_truth_df.withColumn(\"ID\", monotonically_increasing_id())\n",
    "\n",
    "# Join predictions and ground truth on the auto-incrementing ID\n",
    "result_df = predictions_df.join(ground_truth_df, \"ID\", \"inner\")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "result_df.show()\n",
    "\n",
    "# Save the DataFrame as a Hive table\n",
    "result_df.write.mode(\"overwrite\").saveAsTable(\"predictions_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf21b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
